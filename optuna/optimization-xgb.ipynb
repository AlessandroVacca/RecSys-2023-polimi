{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-17T16:04:37.924231353Z",
     "start_time": "2023-12-17T16:04:33.871651292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 213 (1.69 %) of 12638 users have no train items\n",
      "Warning: 2227 (17.62 %) of 12638 users have no sampled items\n",
      "Warning: 455 (3.60 %) of 12638 users have no train items\n",
      "Warning: 2602 (20.59 %) of 12638 users have no sampled items\n"
     ]
    }
   ],
   "source": [
    "from Data_manager.UserUtils import *\n",
    "from Data_manager.split_functions.split_train_validation_random_holdout import \\\n",
    "    split_train_in_two_percentage_global_sample\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "URM_all = getURM_all()\n",
    "URM_train_validation, URM_test = split_train_in_two_percentage_global_sample(URM_all, train_percentage = 0.80)\n",
    "URM_train, URM_validation = split_train_in_two_percentage_global_sample(URM_train_validation, train_percentage = 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Ignoring 2602 (20.6%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 2227 (17.6%) Users that have less than 1 test interactions\n"
     ]
    }
   ],
   "source": [
    "# SETUP EVALUATORS\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "\n",
    "evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=[10])\n",
    "evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T16:04:37.933493285Z",
     "start_time": "2023-12-17T16:04:37.918524393Z"
    }
   },
   "id": "34a9630a540a4a6b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a9fec0ccc4f11c5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T16:04:46.386014389Z",
     "start_time": "2023-12-17T16:04:37.931228464Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:04:38.838379: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-17 17:04:38.838467: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-17 17:04:38.893513: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-17 17:04:39.010631: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-17 17:04:40.315596: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserKNNCFRecommender: URM Detected 455 ( 3.6%) users with no interactions.\n",
      "UserKNNCFRecommender: URM Detected 335 ( 1.5%) items with no interactions.\n",
      "UserKNNCFRecommender: URM Detected 213 ( 1.7%) users with no interactions.\n",
      "UserKNNCFRecommender: URM Detected 117 ( 0.5%) items with no interactions.\n",
      "ItemKNNCFRecommender: URM Detected 455 ( 3.6%) users with no interactions.\n",
      "ItemKNNCFRecommender: URM Detected 335 ( 1.5%) items with no interactions.\n",
      "ItemKNNCFRecommender: URM Detected 213 ( 1.7%) users with no interactions.\n",
      "ItemKNNCFRecommender: URM Detected 117 ( 0.5%) items with no interactions.\n",
      "P3alphaRecommender: URM Detected 455 ( 3.6%) users with no interactions.\n",
      "P3alphaRecommender: URM Detected 335 ( 1.5%) items with no interactions.\n",
      "P3alphaRecommender: URM Detected 213 ( 1.7%) users with no interactions.\n",
      "P3alphaRecommender: URM Detected 117 ( 0.5%) items with no interactions.\n",
      "RP3betaRecommender: URM Detected 455 ( 3.6%) users with no interactions.\n",
      "RP3betaRecommender: URM Detected 335 ( 1.5%) items with no interactions.\n",
      "RP3betaRecommender: URM Detected 213 ( 1.7%) users with no interactions.\n",
      "RP3betaRecommender: URM Detected 117 ( 0.5%) items with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 455 ( 3.6%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 335 ( 1.5%) items with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 213 ( 1.7%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 117 ( 0.5%) items with no interactions.\n",
      "TopPopRecommender: URM Detected 455 ( 3.6%) users with no interactions.\n",
      "TopPopRecommender: URM Detected 335 ( 1.5%) items with no interactions.\n",
      "TopPopRecommender: URM Detected 213 ( 1.7%) users with no interactions.\n",
      "TopPopRecommender: URM Detected 117 ( 0.5%) items with no interactions.\n",
      "MultVAERecommender: URM Detected 455 ( 3.6%) users with no interactions.\n",
      "MultVAERecommender: URM Detected 335 ( 1.5%) items with no interactions.\n",
      "MultVAERecommender: URM Detected 213 ( 1.7%) users with no interactions.\n",
      "MultVAERecommender: URM Detected 117 ( 0.5%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 488/22222 [00:04<01:55, 187.53it/s]Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-3:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[0;32m/usr/lib/python3.10/multiprocessing/pool.py:856\u001B[0m, in \u001B[0;36mIMapIterator.next\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    855\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 856\u001B[0m     item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_items\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpopleft\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    857\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m:\n",
      "\u001B[0;31mIndexError\u001B[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 39\u001B[0m\n\u001B[1;32m     35\u001B[0m     recommender_object \u001B[38;5;241m=\u001B[39m recommender_class(URM_all)\n\u001B[1;32m     36\u001B[0m     recommender_object_dict_all[label] \u001B[38;5;241m=\u001B[39m recommender_object\n\u001B[0;32m---> 39\u001B[0m \u001B[43mrecommender_object_dict_train\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSLIM_ELASTIC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtopK\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8894\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ml1_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.05565733019999427\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.0012979360257937668\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m recommender_object_dict_train[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mP3alpha\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mfit(topK\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m76\u001B[39m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.377201600381895\u001B[39m, normalize_similarity\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     41\u001B[0m recommender_object_dict_train[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRP3beta\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mfit(topK\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m101\u001B[39m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.3026342852596128\u001B[39m, beta\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.058468783118329024\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/projects/rec-sys/RecSys-2023-polimi/Recommenders/SLIM/SLIMElasticNetRecommender.py:240\u001B[0m, in \u001B[0;36mMultiThreadSLIM_SLIMElasticNetRecommender.fit\u001B[0;34m(self, alpha, l1_ratio, positive_only, topK, verbose, workers)\u001B[0m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;66;03m# res contains a vector of (values, rows, cols) tuples\u001B[39;00m\n\u001B[1;32m    239\u001B[0m values, rows, cols \u001B[38;5;241m=\u001B[39m [], [], []\n\u001B[0;32m--> 240\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m values_, rows_, cols_ \u001B[38;5;129;01min\u001B[39;00m pool\u001B[38;5;241m.\u001B[39mimap_unordered(_pfit, itemchunks, pool_chunksize):\n\u001B[1;32m    241\u001B[0m     values\u001B[38;5;241m.\u001B[39mextend(values_)\n\u001B[1;32m    242\u001B[0m     rows\u001B[38;5;241m.\u001B[39mextend(rows_)\n",
      "File \u001B[0;32m/usr/lib/python3.10/multiprocessing/pool.py:451\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    443\u001B[0m result \u001B[38;5;241m=\u001B[39m IMapUnorderedIterator(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    444\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_taskqueue\u001B[38;5;241m.\u001B[39mput(\n\u001B[1;32m    445\u001B[0m     (\n\u001B[1;32m    446\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_guarded_task_generation(result\u001B[38;5;241m.\u001B[39m_job,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    449\u001B[0m         result\u001B[38;5;241m.\u001B[39m_set_length\n\u001B[1;32m    450\u001B[0m     ))\n\u001B[0;32m--> 451\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (item \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m result \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m chunk)\n",
      "File \u001B[0;32m/usr/lib/python3.10/multiprocessing/pool.py:861\u001B[0m, in \u001B[0;36mIMapIterator.next\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pool \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    860\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 861\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    862\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    863\u001B[0m     item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_items\u001B[38;5;241m.\u001B[39mpopleft()\n",
      "File \u001B[0;32m/usr/lib/python3.10/threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from Recommenders.Neural.MultVAERecommender import MultVAERecommender_OptimizerMask\n",
    "from Recommenders.NonPersonalizedRecommender import TopPop\n",
    "from Recommenders.EASE_R.EASE_R_Recommender import EASE_R_Recommender\n",
    "from Recommenders.KNN.UserKNNCFRecommender import UserKNNCFRecommender\n",
    "from Recommenders.KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "from Recommenders.SLIM.SLIMElasticNetRecommender import SLIMElasticNetRecommender, MultiThreadSLIM_SLIMElasticNetRecommender\n",
    "from Recommenders.GraphBased.P3alphaRecommender import P3alphaRecommender\n",
    "from Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "import pickle\n",
    "\n",
    "\n",
    "MAP_recommender_per_group = {}\n",
    "\n",
    "collaborative_recommender_class = {\n",
    "                                   \"UserKNNCF\": UserKNNCFRecommender,\n",
    "                                   \"ItemKNNCF\": ItemKNNCFRecommender,\n",
    "                                   \"P3alpha\": P3alphaRecommender,\n",
    "                                   \"RP3beta\": RP3betaRecommender,\n",
    "                                   \"SLIM_ELASTIC\": MultiThreadSLIM_SLIMElasticNetRecommender,\n",
    "                                   \"TOP_POP\": TopPop,\n",
    "                                    \"MULT_VAE\": MultVAERecommender_OptimizerMask\n",
    "                                   }\n",
    "collaborative_recommender_class.items()\n",
    "\n",
    "recommender_object_dict_train = {}\n",
    "recommender_object_dict_train_validation = {}\n",
    "recommender_object_dict_all = {}\n",
    "for label, recommender_class in collaborative_recommender_class.items():\n",
    "    recommender_object = recommender_class(URM_train)\n",
    "    recommender_object_dict_train[label] = recommender_object\n",
    "    \n",
    "    recommender_object = recommender_class(URM_train_validation)\n",
    "    recommender_object_dict_train_validation[label] = recommender_object\n",
    "    \n",
    "    recommender_object = recommender_class(URM_all)\n",
    "    recommender_object_dict_all[label] = recommender_object\n",
    "    \n",
    "    \n",
    "recommender_object_dict_train[\"SLIM_ELASTIC\"].fit(topK=8894, l1_ratio=0.05565733019999427, alpha=0.0012979360257937668, workers=8)\n",
    "recommender_object_dict_train[\"P3alpha\"].fit(topK=76, alpha=0.377201600381895, normalize_similarity=True)\n",
    "recommender_object_dict_train[\"RP3beta\"].fit(topK=101, alpha=0.3026342852596128, beta=0.058468783118329024)\n",
    "recommender_object_dict_train[\"UserKNNCF\"].fit(topK=469, shrink=38, similarity='asymmetric', normalize=True,\n",
    "                                         feature_weighting='TF-IDF', asymmetric_alpha=0.40077406933762383)\n",
    "recommender_object_dict_train[\"ItemKNNCF\"].fit(topK=31, shrink=435, similarity='tversky', normalize=True,\n",
    "                                       feature_weighting='BM25', tversky_alpha=0.17113169506422393, tversky_beta=0.5684024974085575)\n",
    "recommender_object_dict_train[\"TOP_POP\"].fit()\n",
    "recommender_object_dict_train[\"MULT_VAE\"].fit(topK=101, alpha=0.3026342852596128, beta=0.058468783118329024)\n",
    "\n",
    "recommender_object_dict_train_validation[\"SLIM_ELASTIC\"].fit(topK=8894, l1_ratio=0.05565733019999427, alpha=0.0012979360257937668, workers=8)\n",
    "recommender_object_dict_train_validation[\"P3alpha\"].fit(topK=76, alpha=0.377201600381895, normalize_similarity=True)\n",
    "recommender_object_dict_train_validation[\"RP3beta\"].fit(topK=101, alpha=0.3026342852596128, beta=0.058468783118329024)\n",
    "recommender_object_dict_train_validation[\"UserKNNCF\"].fit(topK=469, shrink=38, similarity='asymmetric', normalize=True,\n",
    "                                         feature_weighting='TF-IDF', asymmetric_alpha=0.40077406933762383)\n",
    "recommender_object_dict_train_validation[\"ItemKNNCF\"].fit(topK=31, shrink=435, similarity='tversky', normalize=True,\n",
    "                                        feature_weighting='BM25', tversky_alpha=0.17113169506422393, tversky_beta=0.5684024974085575)\n",
    "recommender_object_dict_train_validation[\"TOP_POP\"].fit()\n",
    "recommender_object_dict_train_validation[\"MULT_VAE\"].fit(topK=101, alpha=0.3026342852596128, beta=0.058468783118329024)\n",
    "\n",
    "recommender_object_dict_all[\"SLIM_ELASTIC\"].fit(topK=8894, l1_ratio=0.05565733019999427, alpha=0.0012979360257937668, workers=8)\n",
    "recommender_object_dict_all[\"P3alpha\"].fit(topK=76, alpha=0.377201600381895, normalize_similarity=True)\n",
    "recommender_object_dict_all[\"RP3beta\"].fit(topK=101, alpha=0.3026342852596128, beta=0.058468783118329024)\n",
    "recommender_object_dict_all[\"UserKNNCF\"].fit(topK=469, shrink=38, similarity='asymmetric', normalize=True,\n",
    "                                         feature_weighting='TF-IDF', asymmetric_alpha=0.40077406933762383)\n",
    "recommender_object_dict_all[\"ItemKNNCF\"].fit(topK=31, shrink=435, similarity='tversky', normalize=True,\n",
    "                                        feature_weighting='BM25', tversky_alpha=0.17113169506422393, tversky_beta=0.5684024974085575)\n",
    "recommender_object_dict_all[\"TOP_POP\"].fit()\n",
    "recommender_object_dict_all[\"MULT_VAE\"].fit(topK=101, alpha=0.3026342852596128, beta=0.058468783118329024)\n",
    "\n",
    "\n",
    "\n",
    "# save the trained dict objects\n",
    "with open('recommender_object_dict_train.pickle', 'wb') as handle:\n",
    "    pickle.dump(recommender_object_dict_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('recommender_object_dict_train_validation.pickle', 'wb') as handle:\n",
    "    pickle.dump(recommender_object_dict_train_validation, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reload the trained dict objects\n",
    "import pickle\n",
    "with open('recommender_object_dict_train.pickle', 'rb') as handle:\n",
    "    recommender_object_dict_train = pickle.load(handle)\n",
    "with open('recommender_object_dict_train_validation.pickle', 'rb') as handle:\n",
    "    recommender_object_dict_train_validation = pickle.load(handle)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-17T16:04:46.388259295Z"
    }
   },
   "id": "7eae72fe93f618bc"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'Recommenders.XGBoostEnsemble' from '/home/federico/Documents/projects/rec-sys/RecSys-2023-polimi/Recommenders/XGBoostEnsemble.py'>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  Recommenders.XGBoostEnsemble as XgBoostEnsemble\n",
    "from importlib import reload\n",
    "reload(XgBoostEnsemble)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T23:44:57.259709361Z",
     "start_time": "2023-12-10T23:44:57.230712990Z"
    }
   },
   "id": "3ec1c0898360f0ae"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import scipy.sparse as sps\n",
    "# import pandas as pd\n",
    "# import sklearn.svm\n",
    "# import tqdm\n",
    "# import xgboost\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from xgboost import XGBRanker\n",
    "# from Recommenders.BaseRecommender import BaseRecommender\n",
    "# from xgboost import plot_importance\n",
    "# \n",
    "# \n",
    "# class XgBoostEnsembler(BaseRecommender):\n",
    "#     \"\"\"\n",
    "#     This class is used to create an ensemble model using XGBoost.\n",
    "#     It inherits from the BaseRecommender class.\n",
    "#     \"\"\"\n",
    "#     RECOMMENDER_NAME = \"XgBoostEnsembler\"\n",
    "# \n",
    "#     def __init__(self, URM_train, URM_val, recommenders: dict, recommenders_generate_data: dict, internal_cutoff_xgboost=10, verbose=True):\n",
    "#         \"\"\"\n",
    "#         Constructor for the XgBoostEnsembler class.\n",
    "# \n",
    "#         Parameters:\n",
    "#         URM_train (scipy.sparse matrix): The user-item matrix for training.\n",
    "#         URM_val (scipy.sparse matrix): The user-item matrix for validation.\n",
    "#         recommenders (dict): A dictionary of recommenders.\n",
    "#         verbose (bool): A flag used to print detailed logs. Default is True.\n",
    "#         \"\"\"\n",
    "#         super().__init__(URM_train, verbose=verbose)\n",
    "#         self.URM_val = URM_val\n",
    "#         self.recommenders = recommenders\n",
    "#         self.XGB_model = self._init_XGB_model()\n",
    "#         self.internal_cutoff_xgboost = internal_cutoff_xgboost\n",
    "#         self.recommenders_generate_data = recommenders_generate_data\n",
    "#         self.training_dataframe = None\n",
    "# \n",
    "#     def _init_XGB_model(self):\n",
    "#         \"\"\"\n",
    "#         Initializes the XGBoost model with predefined parameters.\n",
    "# \n",
    "#         Returns:\n",
    "#         XGBRanker: The initialized XGBoost model.\n",
    "#         \"\"\"\n",
    "#         return XGBRanker(\n",
    "#             objective='rank:pairwise',\n",
    "#             n_estimators=50,\n",
    "#             learning_rate=1e-1,\n",
    "#             reg_alpha=1e-1,\n",
    "#             reg_lambda=1e-1,\n",
    "#             max_depth=5,\n",
    "#             max_leaves=0,\n",
    "#             grow_policy=\"depthwise\",\n",
    "#             booster=\"gbtree\",\n",
    "#             # eta=0.0506,\n",
    "#             # booster=\"gbtree\",\n",
    "#             # colsample_bytree=0.6113704247857885,\n",
    "#             # gamma=0.09822,\n",
    "#             # min_child_weight=7.0,\n",
    "#             # tree_method=\"hist\",\n",
    "#             verbosity=1,\n",
    "#             # max_depth=3, learning_rate=0.1, n_estimators=100,\n",
    "#             # silent=True, objective=\"rank:pairwise\", booster='gbtree',\n",
    "#             # n_jobs=-1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0,\n",
    "#             # subsample=1, colsample_bytree=1, colsample_bylevel=1,\n",
    "#             # reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "#             # base_score=0.5,\n",
    "# \n",
    "#         )\n",
    "#         return xgboost.XGBRanker()\n",
    "#         # return sklearn.linear_model.Ridge()\n",
    "# \n",
    "#     def _create_training_dataframe(self, users):\n",
    "#         \"\"\"\n",
    "#         Creates a training dataframe with user IDs and their corresponding item recommendations.\n",
    "# \n",
    "#         Parameters:\n",
    "#         n_users (int): The number of users.\n",
    "# \n",
    "#         Returns:\n",
    "#         DataFrame: The training dataframe.\n",
    "#         \"\"\"\n",
    "# \n",
    "#         print(\"Creating training dataframe...\")\n",
    "#         training_dataframe = pd.DataFrame(index=users, columns=[\"ItemID\"])\n",
    "#         training_dataframe[\"UserID\"] = users\n",
    "#         # training_dataframe.index.name = 'UserID'\n",
    "# \n",
    "#         all_user_recommendations = np.zeros((len(users), self.internal_cutoff_xgboost * len(self.recommenders_generate_data)), dtype=np.int64)\n",
    "# \n",
    "#         for i, (_, rec_instance) in enumerate(self.recommenders_generate_data.items()):\n",
    "#             recs = rec_instance.recommend(users, cutoff=self.internal_cutoff_xgboost)\n",
    "#             all_user_recommendations[:, i*self.internal_cutoff_xgboost:(i+1)*self.internal_cutoff_xgboost] = recs\n",
    "# \n",
    "#         training_dataframe[\"ItemID\"] = all_user_recommendations.tolist()\n",
    "# \n",
    "#         return training_dataframe.explode(\"ItemID\").drop_duplicates()\n",
    "# \n",
    "#     def _populate_training_dataframe_label(self, training_dataframe):\n",
    "#         print(\"Populating training dataframe with labels...\")\n",
    "#         urm_validation_coo = sps.coo_matrix(self.URM_val)\n",
    "# \n",
    "#         correct_recommendations = pd.DataFrame({\"UserID\": urm_validation_coo.row,\n",
    "#                                                 \"ItemID\": urm_validation_coo.col})\n",
    "#         training_dataframe = pd.merge(training_dataframe, correct_recommendations, on=['UserID', 'ItemID'], how='left',\n",
    "#                                       indicator='Exist')\n",
    "# \n",
    "#         training_dataframe[\"Label\"] = training_dataframe[\"Exist\"] == \"both\"\n",
    "#         training_dataframe.drop(columns=['Exist'], inplace=True)\n",
    "#         # training_dataframe = training_dataframe.set_index('UserID')\n",
    "# \n",
    "#         print(\"Percentage of positive samples: {:.2f}%\".format(\n",
    "#             training_dataframe[\"Label\"].sum() / training_dataframe.shape[0] * 100))\n",
    "# \n",
    "#         return training_dataframe\n",
    "# \n",
    "#     def _populate_training_dataframe(self, training_dataframe, users):\n",
    "#         \"\"\"\n",
    "#         Populates the training dataframe with item scores from each recommender.\n",
    "# \n",
    "#         Parameters:\n",
    "#         training_dataframe (DataFrame): The training dataframe.\n",
    "#         n_users (int): The number of users.\n",
    "# \n",
    "#         Returns:\n",
    "#         DataFrame: The populated training dataframe.\n",
    "#         \"\"\"\n",
    "#         # for user_id in tqdm.tqdm(users):\n",
    "#         #     for rec_label, rec_instance in self.recommenders.items():\n",
    "#         #         item_list = training_dataframe.loc[user_id, \"ItemID\"].values.tolist()\n",
    "#         #         all_item_scores = rec_instance._compute_item_score([user_id], items_to_compute=item_list)\n",
    "#         #         training_dataframe.loc[user_id, rec_label] = all_item_scores[0, item_list]\n",
    "# \n",
    "#         print(\"Populating training dataframe with item scores...\")\n",
    "#         for rec_label, rec_instance in tqdm.tqdm(self.recommenders.items()):\n",
    "#             all_user_scores = rec_instance._compute_item_score(users)  # Predict items for all users at once\n",
    "#             map_user_to_index = {user_id: index for index, user_id in enumerate(users)}\n",
    "#             user_index_pairs = training_dataframe[[\"UserID\", \"ItemID\"]].values.astype(np.int64)\n",
    "#             users_indexes = [map_user_to_index[user_id] for user_id in user_index_pairs[:,0]]\n",
    "# \n",
    "#             training_dataframe[rec_label] = all_user_scores[users_indexes, user_index_pairs[:, 1]]\n",
    "# \n",
    "# \n",
    "#         item_popularity = np.ediff1d(sps.csc_matrix(self.URM_train).indptr)\n",
    "#         training_dataframe['item_popularity'] = item_popularity[training_dataframe[\"ItemID\"].values.astype(int)]\n",
    "# \n",
    "#         user_popularity = np.ediff1d(sps.csr_matrix(self.URM_train).indptr)\n",
    "#         training_dataframe['user_profile_len'] = user_popularity[training_dataframe[\"UserID\"].values.astype(int)]\n",
    "# \n",
    "#         training_dataframe = training_dataframe.sort_values(\"UserID\").reset_index()\n",
    "#         training_dataframe.drop(columns=['index'], inplace=True)\n",
    "#         training_dataframe[\"ItemID\"] = training_dataframe[\"ItemID\"].astype('int64')\n",
    "#         return training_dataframe\n",
    "# \n",
    "#     def fit(self, plot=False, prepare_training_df=True):\n",
    "#         \"\"\"\n",
    "#         Trains the XGBoost model.\n",
    "#         \"\"\"\n",
    "#         self.XGB_model = self._init_XGB_model()\n",
    "#         if prepare_training_df or self.training_dataframe is None:\n",
    "#             n_users, n_items = self.URM_train.shape\n",
    "#             training_dataframe = self._create_training_dataframe(range(n_users))\n",
    "#             training_dataframe = self._populate_training_dataframe_label(training_dataframe)\n",
    "#             self.training_dataframe = self._populate_training_dataframe(training_dataframe, range(n_users))\n",
    "# \n",
    "#         X = self.training_dataframe.drop(columns=[\"Label\"])\n",
    "#         y = self.training_dataframe[\"Label\"]\n",
    "#         groups = self.training_dataframe.groupby(\"UserID\").size().values\n",
    "# \n",
    "#         # Splitting X, y into train and validation sets\n",
    "#         X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=False)\n",
    "# \n",
    "#         # Creating groups for train and validation sets\n",
    "#         groups_train = X_train.groupby(\"UserID\").size().values\n",
    "#         groups_val = X_val.groupby(\"UserID\").size().values\n",
    "# \n",
    "#         # X_train = X_train.drop(columns=[\"UserID\", \"ItemID\"])\n",
    "#         # X_val = X_val.drop(columns=[\"UserID\", \"ItemID\"])\n",
    "# \n",
    "#         # evals = [(X_train, y_train), (X_val, y_val)]\n",
    "# \n",
    "#         # groups = training_dataframe.groupby(\"UserID\").size().values\n",
    "#         # self.XGB_model.fit(X_train, y_train, group=groups, verbose=True, eval_set=[(X_test, y_test)], eval_group=groups, early_stopping_rounds=10, eval_metric=[\"auc\",\"error\"])\n",
    "#         # self.XGB_model.fit(\n",
    "#         #     X_train, y_train, group=groups_train, verbose=True, eval_set=evals, eval_group=[groups_train, groups_val], early_stopping_rounds=10,\n",
    "#         #      eval_metric=['map@10']\n",
    "#         # )\n",
    "#         # self.XGB_model.fit(\n",
    "#         #     X_train, y_train,\n",
    "#         #     # verbose=True, #eval_set=evals,\n",
    "#         #     # early_stopping_rounds=10,\n",
    "#         #     # eval_metric=['merror']\n",
    "#         # )\n",
    "#         self.XGB_model.fit(X_train, y_train, group=groups_train, verbose=True)\n",
    "#         y_est = self.XGB_model.predict(X_val)\n",
    "#         # MAP\n",
    "#         print(\"MSE: {:.2f}\".format(np.mean((y_val - y_est) ** 2)))\n",
    "# \n",
    "#         # self.XGB_model.fit(X_train, y_val)\n",
    "#         if plot:\n",
    "#             plot_importance(self.XGB_model, importance_type='weight', title='Weight (Frequence)')\n",
    "# \n",
    "#     def _compute_item_score(self, user_id_array, items_to_compute=None):\n",
    "#         \"\"\"\n",
    "#         Computes the item scores for a given array of user IDs.\n",
    "# \n",
    "#         Parameters:\n",
    "#         user_id_array (array): The array of user IDs.\n",
    "#         items_to_compute (array): The array of items to compute scores for. Default is None.\n",
    "# \n",
    "#         Returns:\n",
    "#         array: The array of item scores.\n",
    "#         \"\"\"\n",
    "#         n_users, n_items = self.URM_train.shape\n",
    "#         training_dataframe = self._create_training_dataframe(user_id_array)\n",
    "#         training_dataframe = self._populate_training_dataframe(training_dataframe, user_id_array)\n",
    "#         X_train = training_dataframe\n",
    "#         # X_train = training_dataframe.drop(columns=[\"UserID\", \"ItemID\"])\n",
    "#         predictions = self.XGB_model.predict(X_train)\n",
    "#         return self._rerank_items(predictions, training_dataframe, user_id_array, n_items)\n",
    "# \n",
    "#     def _rerank_items(self, predictions, training_dataframe, user_id_array, n_items):\n",
    "#         \"\"\"\n",
    "#         Reranks the items based on the predictions from the XGBoost model.\n",
    "# \n",
    "#         Parameters:\n",
    "#         predictions (array): The array of predictions from the XGBoost model.\n",
    "#         training_dataframe (DataFrame): The training dataframe.\n",
    "#         user_id_array (array): The array of user IDs.\n",
    "#         n_items (int): The number of items.\n",
    "# \n",
    "#         Returns:\n",
    "#         array: The array of reranked item scores.\n",
    "#         \"\"\"\n",
    "#         reranked_dataframe = training_dataframe.copy()\n",
    "#         reranked_dataframe['rating_xgb'] = pd.Series(predictions, index=reranked_dataframe.index)\n",
    "#         reranked_dataframe = reranked_dataframe.sort_values(['UserID', 'rating_xgb'], ascending=[True, False])\n",
    "#         result = []\n",
    "#         for id in tqdm.tqdm(user_id_array):\n",
    "#             items_scores = np.ones(n_items) * (-100000000)\n",
    "#             items_scores[reranked_dataframe.loc[reranked_dataframe['UserID'] == id].ItemID.values.astype(int)] = \\\n",
    "#                 reranked_dataframe.loc[reranked_dataframe['UserID'] == id].rating_xgb.values\n",
    "#             result.append(items_scores)\n",
    "#         return np.array(result)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T15:44:58.899967039Z",
     "start_time": "2023-12-17T15:44:58.826634130Z"
    }
   },
   "id": "9611ad90cbe0dd3e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TRY to use the XGBoostEnsemble"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89c2e5c5187690b4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XgBoostEnsembler: URM Detected 455 ( 3.6%) users with no interactions.\n",
      "XgBoostEnsembler: URM Detected 335 ( 1.5%) items with no interactions.\n",
      "Creating training dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating training dataframe with labels...\n",
      "Percentage of positive samples: 3.07%\n",
      "Populating training dataframe with item scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:09<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.41\n"
     ]
    }
   ],
   "source": [
    "# import  Recommenders.XGBoostEnsemble as XgBoostEnsemble\n",
    "# from importlib import reload\n",
    "# reload(XgBoostEnsemble)\n",
    "\n",
    "xgb_ranker_params = {\n",
    "    \"objective\": \"rank:pairwise\",\n",
    "    \"n_estimators\": 50,\n",
    "    \"learning_rate\": 1e-1,\n",
    "    \"reg_alpha\": 1e-1,\n",
    "    \"reg_lambda\": 1e-1,\n",
    "    \"max_depth\": 5,\n",
    "    \"max_leaves\": 0,\n",
    "    \"grow_policy\": \"depthwise\",\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"verbosity\": 1,\n",
    "}\n",
    "model = XgBoostEnsembler(URM_train, URM_val=URM_validation, recommenders=recommender_object_dict_train, recommenders_generate_data=recommender_object_dict_train)\n",
    "\n",
    "model.fit(**xgb_ranker_params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T15:45:34.032516933Z",
     "start_time": "2023-12-17T15:45:00.347050527Z"
    }
   },
   "id": "e4a745365b681791"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating training dataframe with item scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.64it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 596.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating training dataframe with item scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.52it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 595.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating training dataframe with item scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.83it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 603.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating training dataframe with item scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.83it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 588.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating training dataframe with item scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.82it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 605.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating training dataframe with item scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.86it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 606.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating training dataframe with item scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.55it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 617.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating training dataframe with item scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.86it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 607.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating training dataframe with item scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.15it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 611.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating training dataframe with item scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.76it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 582.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:00,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating training dataframe with item scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 16.44it/s]\n",
      "100%|██████████| 411/411 [00:00<00:00, 564.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10411 (100.0%) in 51.49 sec. Users per second: 202\n"
     ]
    },
    {
     "data": {
      "text/plain": "(       PRECISION PRECISION_RECALL_MIN_DEN    RECALL       MAP MAP_MIN_DEN  \\\n cutoff                                                                      \n 10      0.099491                 0.175275  0.148429  0.050748    0.087589   \n \n             MRR      NDCG       F1  HIT_RATE ARHR_ALL_HITS  ... COVERAGE_USER  \\\n cutoff                                                      ...                 \n 10      0.27906  0.157536  0.11913  0.539622      0.371389  ...      0.823785   \n \n        COVERAGE_USER_HIT USERS_IN_GT DIVERSITY_GINI SHANNON_ENTROPY  \\\n cutoff                                                                \n 10              0.444532    0.823785        0.04774        9.778185   \n \n        RATIO_DIVERSITY_HERFINDAHL RATIO_DIVERSITY_GINI RATIO_SHANNON_ENTROPY  \\\n cutoff                                                                         \n 10                       0.995834             0.138732              0.753987   \n \n        RATIO_AVERAGE_POPULARITY RATIO_NOVELTY  \n cutoff                                         \n 10                     2.236912      0.348166  \n \n [1 rows x 27 columns],\n 'CUTOFF: 10 - PRECISION: 0.0994909, PRECISION_RECALL_MIN_DEN: 0.1752747, RECALL: 0.1484285, MAP: 0.0507483, MAP_MIN_DEN: 0.0875891, MRR: 0.2790605, NDCG: 0.1575364, F1: 0.1191297, HIT_RATE: 0.5396216, ARHR_ALL_HITS: 0.3713889, NOVELTY: 0.0049259, AVERAGE_POPULARITY: 0.2766380, DIVERSITY_MEAN_INTER_LIST: 0.9548133, DIVERSITY_HERFINDAHL: 0.9954722, COVERAGE_ITEM: 0.2687427, COVERAGE_ITEM_HIT: 0.0986860, ITEMS_IN_GT: 0.8073081, COVERAGE_USER: 0.8237854, COVERAGE_USER_HIT: 0.4445324, USERS_IN_GT: 0.8237854, DIVERSITY_GINI: 0.0477400, SHANNON_ENTROPY: 9.7781847, RATIO_DIVERSITY_HERFINDAHL: 0.9958335, RATIO_DIVERSITY_GINI: 0.1387317, RATIO_SHANNON_ENTROPY: 0.7539866, RATIO_AVERAGE_POPULARITY: 2.2369118, RATIO_NOVELTY: 0.3481657, \\n')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.recommenders_generate_data = recommender_object_dict_train_validation\n",
    "model.recommenders = recommender_object_dict_train_validation\n",
    "evaluator_test.evaluateRecommender(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T15:46:25.591707287Z",
     "start_time": "2023-12-17T15:45:34.034705703Z"
    }
   },
   "id": "bde63243ebe54a63"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating recommender: UserKNNCF\n",
      "EvaluatorHoldout: Processed 10411 (100.0%) in 8.81 sec. Users per second: 1182\n",
      "0.03582347654266798\n",
      "Evaluating recommender: ItemKNNCF\n",
      "EvaluatorHoldout: Processed 10411 (100.0%) in 7.40 sec. Users per second: 1407\n",
      "0.04596670493510432\n",
      "Evaluating recommender: P3alpha\n",
      "EvaluatorHoldout: Processed 10411 (100.0%) in 5.69 sec. Users per second: 1831\n",
      "0.04764005333187027\n",
      "Evaluating recommender: RP3beta\n",
      "EvaluatorHoldout: Processed 10411 (100.0%) in 5.87 sec. Users per second: 1775\n",
      "0.04749910808622816\n",
      "Evaluating recommender: SLIM_ELASTIC\n",
      "EvaluatorHoldout: Processed 10411 (100.0%) in 7.87 sec. Users per second: 1322\n",
      "0.05021803480140885\n",
      "Evaluating recommender: TOP_POP\n",
      "EvaluatorHoldout: Processed 10411 (100.0%) in 5.65 sec. Users per second: 1842\n",
      "0.012087829112370427\n"
     ]
    }
   ],
   "source": [
    "#evaluate recommenders\n",
    "for label, recommender in recommender_object_dict_train_validation.items():\n",
    "    print(\"Evaluating recommender: {}\".format(label))\n",
    "    result_dict, _ = evaluator_test.evaluateRecommender(recommender)\n",
    "    print(result_dict[\"MAP\"].item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T15:48:27.888430178Z",
     "start_time": "2023-12-17T15:47:46.526862523Z"
    }
   },
   "id": "ca2357c8b0d8ac28"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b826576f6714c764",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T22:15:54.859571644Z",
     "start_time": "2023-12-10T22:15:54.838602615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XgBoostEnsembler: URM Detected 429 ( 3.4%) users with no interactions.\n",
      "XgBoostEnsembler: URM Detected 333 ( 1.5%) items with no interactions.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRanker\n",
    "from Recommenders.XGBoostEnsemble import XgBoostEnsembler\n",
    "\n",
    "import optuna as op\n",
    "import xgboost as xgb\n",
    "\n",
    "model2 = XgBoostEnsembler(URM_train, URM_val=URM_validation, recommenders=)\n",
    "\n",
    "model2.training_dataframe = model.training_dataframe\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        \"verbosity\": 0,\n",
    "        \"objective\": \"rank:pairwise\",\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-8, 1.0, log=True),\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\"]),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 1.0, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 1.0, log=True),\n",
    "    }\n",
    "\n",
    "    if param[\"booster\"] == \"gbtree\":\n",
    "        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 9)\n",
    "        param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
    "        param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "        param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "    # xgb_model = XGBRanker(**param)\n",
    "    # XGBRanker(\n",
    "    #     objective='rank:pairwise',\n",
    "    #     n_estimators=1000,\n",
    "    #     learning_rate=0.19823429576094637,\n",
    "    #     reg_alpha=47,\n",
    "    #     reg_lambda=0.313,\n",
    "    #     max_depth=3,\n",
    "    #     verbosity=0,\n",
    "    #     booster=\"gbtree\",\n",
    "    #     colsample_bytree=0.6113704247857885,\n",
    "    #     gamma=8.964184693722684,\n",
    "    #     min_child_weight=7.0,\n",
    "    #     tree_method=\"hist\"\n",
    "    # )\n",
    "    # Add a callback for pruning.\n",
    "    #pruning_callback = op.integration.XGBoostPruningCallback(trial, \"validation-auc\")\n",
    "    model.fit(prepare_training_df=False)\n",
    "        \n",
    "    result, _ = evaluator_test.evaluateRecommender(model)\n",
    "    MAP_result = result[\"MAP\"].item()\n",
    "       \n",
    "    return MAP_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8a36d4aed08fc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \n",
    "}\n",
    "\n",
    "study_name = \"XGB-study-2\"  # Unique identifier of the study.\n",
    "storage_name = \"sqlite:///db.db\"\n",
    "study = op.create_study(study_name=study_name, storage=storage_name, direction=\"maximize\",pruner=op.pruners.MedianPruner(n_warmup_steps=5), load_if_exists=True)\n",
    "#study.enqueue_trial(best_params)\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XgBoostEnsembler: URM Detected 429 ( 3.4%) users with no interactions.\n",
      "XgBoostEnsembler: URM Detected 333 ( 1.5%) items with no interactions.\n"
     ]
    }
   ],
   "source": [
    "import  Recommenders.XGBoostEnsemble as XgBoostEnsemble\n",
    "from importlib import reload\n",
    "reload(XgBoostEnsemble)\n",
    "model = XgBoostEnsemble.XgBoostEnsembler(URM_train, URM_val=URM_validation, recommenders=recommender_object_dict)\n",
    "model.training_dataframe = td_f\n",
    "model.fit(prepare_training_df=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T00:04:37.671814481Z",
     "start_time": "2023-12-11T00:04:37.560705901Z"
    }
   },
   "id": "40ff8f62a1530c0d"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a0a3570fbcb348b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T00:05:47.304506446Z",
     "start_time": "2023-12-11T00:04:40.518724684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Ignoring 2162 (17.1%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 0 Users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:00<00:03,  1.62it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:01<00:02,  1.72it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:01<00:01,  1.86it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.93it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:02<00:00,  1.85it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001B[A\n",
      "  3%|▎         | 31/1000 [00:00<00:03, 308.48it/s]\u001B[A\n",
      "  9%|▉         | 88/1000 [00:00<00:01, 461.13it/s]\u001B[A\n",
      " 15%|█▌        | 153/1000 [00:00<00:01, 544.34it/s]\u001B[A\n",
      " 21%|██▏       | 213/1000 [00:00<00:01, 563.80it/s]\u001B[A\n",
      " 28%|██▊       | 275/1000 [00:00<00:01, 581.15it/s]\u001B[A\n",
      " 33%|███▎      | 334/1000 [00:00<00:01, 575.81it/s]\u001B[A\n",
      " 39%|███▉      | 392/1000 [00:00<00:01, 575.60it/s]\u001B[A\n",
      " 45%|████▌     | 452/1000 [00:00<00:00, 582.60it/s]\u001B[A\n",
      " 51%|█████▏    | 514/1000 [00:00<00:00, 592.03it/s]\u001B[A\n",
      " 57%|█████▋    | 574/1000 [00:01<00:00, 593.57it/s]\u001B[A\n",
      " 64%|██████▎   | 637/1000 [00:01<00:00, 604.01it/s]\u001B[A\n",
      " 70%|██████▉   | 698/1000 [00:01<00:00, 588.75it/s]\u001B[A\n",
      " 76%|███████▌  | 761/1000 [00:01<00:00, 598.42it/s]\u001B[A\n",
      " 82%|████████▏ | 821/1000 [00:01<00:00, 595.25it/s]\u001B[A\n",
      " 88%|████████▊ | 881/1000 [00:01<00:00, 592.32it/s]\u001B[A\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 577.30it/s][A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:00<00:02,  1.67it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:01<00:02,  1.76it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:01<00:01,  1.88it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.96it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:02<00:00,  1.86it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.92it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001B[A\n",
      "  4%|▍         | 38/1000 [00:00<00:02, 376.43it/s]\u001B[A\n",
      " 10%|█         | 103/1000 [00:00<00:01, 533.59it/s]\u001B[A\n",
      " 17%|█▋        | 169/1000 [00:00<00:01, 587.20it/s]\u001B[A\n",
      " 23%|██▎       | 228/1000 [00:00<00:01, 588.24it/s]\u001B[A\n",
      " 29%|██▉       | 290/1000 [00:00<00:01, 598.81it/s]\u001B[A\n",
      " 35%|███▌      | 350/1000 [00:00<00:01, 596.04it/s]\u001B[A\n",
      " 41%|████      | 410/1000 [00:00<00:00, 594.52it/s]\u001B[A\n",
      " 47%|████▋     | 471/1000 [00:00<00:00, 598.19it/s]\u001B[A\n",
      " 53%|█████▎    | 531/1000 [00:00<00:00, 598.46it/s]\u001B[A\n",
      " 59%|█████▉    | 594/1000 [00:01<00:00, 606.26it/s]\u001B[A\n",
      " 66%|██████▌   | 655/1000 [00:01<00:00, 597.30it/s]\u001B[A\n",
      " 72%|███████▏  | 715/1000 [00:01<00:00, 587.64it/s]\u001B[A\n",
      " 77%|███████▋  | 774/1000 [00:01<00:00, 584.12it/s]\u001B[A\n",
      " 83%|████████▎ | 834/1000 [00:01<00:00, 587.29it/s]\u001B[A\n",
      " 89%|████████▉ | 893/1000 [00:01<00:00, 584.63it/s]\u001B[A\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 583.14it/s][A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:00<00:02,  1.69it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:01<00:02,  1.77it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:01<00:01,  1.90it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.96it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:02<00:00,  1.84it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.91it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001B[A\n",
      "  4%|▍         | 40/1000 [00:00<00:02, 398.39it/s]\u001B[A\n",
      " 10%|█         | 103/1000 [00:00<00:01, 533.25it/s]\u001B[A\n",
      " 16%|█▋        | 164/1000 [00:00<00:01, 567.87it/s]\u001B[A\n",
      " 22%|██▎       | 225/1000 [00:00<00:01, 583.83it/s]\u001B[A\n",
      " 29%|██▊       | 286/1000 [00:00<00:01, 592.90it/s]\u001B[A\n",
      " 35%|███▍      | 346/1000 [00:00<00:01, 594.08it/s]\u001B[A\n",
      " 41%|████      | 407/1000 [00:00<00:00, 598.63it/s]\u001B[A\n",
      " 47%|████▋     | 467/1000 [00:00<00:00, 598.19it/s]\u001B[A\n",
      " 53%|█████▎    | 527/1000 [00:00<00:00, 592.51it/s]\u001B[A\n",
      " 59%|█████▊    | 587/1000 [00:01<00:00, 583.67it/s]\u001B[A\n",
      " 65%|██████▍   | 646/1000 [00:01<00:00, 577.46it/s]\u001B[A\n",
      " 70%|███████   | 705/1000 [00:01<00:00, 579.74it/s]\u001B[A\n",
      " 76%|███████▋  | 765/1000 [00:01<00:00, 583.19it/s]\u001B[A\n",
      " 82%|████████▏ | 824/1000 [00:01<00:00, 583.73it/s]\u001B[A\n",
      " 88%|████████▊ | 883/1000 [00:01<00:00, 577.43it/s]\u001B[A\n",
      " 94%|█████████▍| 941/1000 [00:01<00:00, 561.87it/s]\u001B[A\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 575.42it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:00<00:03,  1.43it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:01<00:02,  1.65it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:01<00:01,  1.71it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.67it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.59it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001B[A\n",
      "  4%|▍         | 39/1000 [00:00<00:02, 385.89it/s]\u001B[A\n",
      "  9%|▉         | 89/1000 [00:00<00:02, 446.52it/s]\u001B[A\n",
      " 14%|█▍        | 142/1000 [00:00<00:01, 482.49it/s]\u001B[A\n",
      " 21%|██        | 206/1000 [00:00<00:01, 544.12it/s]\u001B[A\n",
      " 28%|██▊       | 275/1000 [00:00<00:01, 592.89it/s]\u001B[A\n",
      " 34%|███▍      | 339/1000 [00:00<00:01, 608.24it/s]\u001B[A\n",
      " 40%|████      | 403/1000 [00:00<00:00, 617.38it/s]\u001B[A\n",
      " 46%|████▋     | 465/1000 [00:00<00:00, 571.52it/s]\u001B[A\n",
      " 52%|█████▏    | 523/1000 [00:00<00:00, 525.54it/s]\u001B[A\n",
      " 58%|█████▊    | 584/1000 [00:01<00:00, 548.58it/s]\u001B[A\n",
      " 65%|██████▍   | 647/1000 [00:01<00:00, 571.28it/s]\u001B[A\n",
      " 71%|███████   | 712/1000 [00:01<00:00, 592.38it/s]\u001B[A\n",
      " 77%|███████▋  | 772/1000 [00:01<00:00, 589.79it/s]\u001B[A\n",
      " 83%|████████▎ | 832/1000 [00:01<00:00, 528.48it/s]\u001B[A\n",
      " 89%|████████▊ | 887/1000 [00:01<00:00, 483.25it/s]\u001B[A\n",
      " 94%|█████████▍| 943/1000 [00:01<00:00, 502.51it/s]\u001B[A\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 538.33it/s][A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:00<00:03,  1.48it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:01<00:02,  1.62it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:01<00:01,  1.80it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.88it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:02<00:00,  1.79it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.82it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001B[A\n",
      "  5%|▍         | 46/1000 [00:00<00:02, 456.51it/s]\u001B[A\n",
      " 10%|█         | 101/1000 [00:00<00:01, 508.43it/s]\u001B[A\n",
      " 15%|█▌        | 152/1000 [00:00<00:01, 491.42it/s]\u001B[A\n",
      " 20%|██        | 202/1000 [00:00<00:01, 476.14it/s]\u001B[A\n",
      " 26%|██▌       | 255/1000 [00:00<00:01, 491.53it/s]\u001B[A\n",
      " 30%|███       | 305/1000 [00:00<00:01, 490.56it/s]\u001B[A\n",
      " 37%|███▋      | 367/1000 [00:00<00:01, 531.05it/s]\u001B[A\n",
      " 43%|████▎     | 433/1000 [00:00<00:00, 569.49it/s]\u001B[A\n",
      " 50%|████▉     | 498/1000 [00:00<00:00, 594.00it/s]\u001B[A\n",
      " 56%|█████▋    | 563/1000 [00:01<00:00, 609.61it/s]\u001B[A\n",
      " 63%|██████▎   | 626/1000 [00:01<00:00, 615.04it/s]\u001B[A\n",
      " 69%|██████▉   | 690/1000 [00:01<00:00, 621.26it/s]\u001B[A\n",
      " 76%|███████▌  | 755/1000 [00:01<00:00, 627.04it/s]\u001B[A\n",
      " 82%|████████▏ | 819/1000 [00:01<00:00, 630.92it/s]\u001B[A\n",
      " 88%|████████▊ | 883/1000 [00:01<00:00, 629.46it/s]\u001B[A\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 582.61it/s][A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:00<00:03,  1.33it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:01<00:02,  1.61it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:01<00:01,  1.83it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.94it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:02<00:00,  1.87it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001B[A\n",
      "  4%|▍         | 44/1000 [00:00<00:02, 435.56it/s]\u001B[A\n",
      " 11%|█▏        | 113/1000 [00:00<00:01, 583.47it/s]\u001B[A\n",
      " 18%|█▊        | 181/1000 [00:00<00:01, 625.68it/s]\u001B[A\n",
      " 25%|██▍       | 246/1000 [00:00<00:01, 634.43it/s]\u001B[A\n",
      " 31%|███       | 310/1000 [00:00<00:01, 628.92it/s]\u001B[A\n",
      " 37%|███▋      | 373/1000 [00:00<00:01, 622.24it/s]\u001B[A\n",
      " 44%|████▍     | 439/1000 [00:00<00:00, 631.89it/s]\u001B[A\n",
      " 50%|█████     | 504/1000 [00:00<00:00, 634.77it/s]\u001B[A\n",
      " 57%|█████▋    | 568/1000 [00:00<00:00, 628.00it/s]\u001B[A\n",
      " 63%|██████▎   | 632/1000 [00:01<00:00, 631.54it/s]\u001B[A\n",
      " 70%|██████▉   | 698/1000 [00:01<00:00, 639.35it/s]\u001B[A\n",
      " 76%|███████▋  | 764/1000 [00:01<00:00, 644.37it/s]\u001B[A\n",
      " 83%|████████▎ | 830/1000 [00:01<00:00, 647.38it/s]\u001B[A\n",
      " 90%|████████▉ | 895/1000 [00:01<00:00, 641.67it/s]\u001B[A\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 628.87it/s][A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:00<00:02,  1.68it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:01<00:02,  1.78it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:01<00:01,  1.91it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.98it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:02<00:00,  1.89it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.94it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001B[A\n",
      "  4%|▍         | 45/1000 [00:00<00:02, 447.75it/s]\u001B[A\n",
      " 11%|█▏        | 114/1000 [00:00<00:01, 587.63it/s]\u001B[A\n",
      " 18%|█▊        | 183/1000 [00:00<00:01, 634.18it/s]\u001B[A\n",
      " 25%|██▌       | 250/1000 [00:00<00:01, 647.87it/s]\u001B[A\n",
      " 32%|███▏      | 317/1000 [00:00<00:01, 655.79it/s]\u001B[A\n",
      " 38%|███▊      | 383/1000 [00:00<00:00, 651.18it/s]\u001B[A\n",
      " 45%|████▍     | 449/1000 [00:00<00:00, 650.92it/s]\u001B[A\n",
      " 52%|█████▏    | 515/1000 [00:00<00:00, 646.58it/s]\u001B[A\n",
      " 58%|█████▊    | 580/1000 [00:00<00:00, 643.19it/s]\u001B[A\n",
      " 64%|██████▍   | 645/1000 [00:01<00:00, 645.13it/s]\u001B[A\n",
      " 71%|███████   | 710/1000 [00:01<00:00, 643.39it/s]\u001B[A\n",
      " 78%|███████▊  | 776/1000 [00:01<00:00, 646.55it/s]\u001B[A\n",
      " 84%|████████▍ | 841/1000 [00:01<00:00, 643.51it/s]\u001B[A\n",
      " 91%|█████████ | 906/1000 [00:01<00:00, 636.48it/s]\u001B[A\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 636.67it/s][A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:00<00:02,  1.70it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:01<00:02,  1.70it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:01<00:01,  1.63it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.71it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.53it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.60it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001B[A\n",
      "  2%|▎         | 25/1000 [00:00<00:03, 246.42it/s]\u001B[A\n",
      "  7%|▋         | 74/1000 [00:00<00:02, 385.54it/s]\u001B[A\n",
      " 12%|█▎        | 125/1000 [00:00<00:01, 440.15it/s]\u001B[A\n",
      " 18%|█▊        | 181/1000 [00:00<00:01, 486.49it/s]\u001B[A\n",
      " 24%|██▎       | 237/1000 [00:00<00:01, 512.35it/s]\u001B[A\n",
      " 29%|██▉       | 291/1000 [00:00<00:01, 521.62it/s]\u001B[A\n",
      " 34%|███▍      | 344/1000 [00:00<00:01, 519.33it/s]\u001B[A\n",
      " 40%|███▉      | 396/1000 [00:00<00:01, 510.67it/s]\u001B[A\n",
      " 45%|████▌     | 452/1000 [00:00<00:01, 524.82it/s]\u001B[A\n",
      " 51%|█████     | 508/1000 [00:01<00:00, 535.17it/s]\u001B[A\n",
      " 57%|█████▋    | 566/1000 [00:01<00:00, 547.96it/s]\u001B[A\n",
      " 62%|██████▏   | 621/1000 [00:01<00:00, 547.82it/s]\u001B[A\n",
      " 68%|██████▊   | 680/1000 [00:01<00:00, 558.54it/s]\u001B[A\n",
      " 74%|███████▎  | 737/1000 [00:01<00:00, 559.71it/s]\u001B[A\n",
      " 80%|████████  | 800/1000 [00:01<00:00, 580.68it/s]\u001B[A\n",
      " 86%|████████▋ | 864/1000 [00:01<00:00, 597.63it/s]\u001B[A\n",
      " 93%|█████████▎| 929/1000 [00:01<00:00, 612.81it/s]\u001B[A\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 546.13it/s][A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:00<00:02,  1.75it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:01<00:02,  1.84it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:01<00:01,  1.99it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:02<00:00,  2.05it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:02<00:00,  1.89it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.94it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001B[A\n",
      "  4%|▍         | 41/1000 [00:00<00:02, 408.37it/s]\u001B[A\n",
      " 10%|█         | 102/1000 [00:00<00:01, 523.45it/s]\u001B[A\n",
      " 16%|█▋        | 164/1000 [00:00<00:01, 566.93it/s]\u001B[A\n",
      " 22%|██▏       | 222/1000 [00:00<00:01, 569.73it/s]\u001B[A\n",
      " 28%|██▊       | 280/1000 [00:00<00:01, 573.05it/s]\u001B[A\n",
      " 34%|███▍      | 338/1000 [00:00<00:01, 567.73it/s]\u001B[A\n",
      " 40%|███▉      | 395/1000 [00:00<00:01, 547.61it/s]\u001B[A\n",
      " 45%|████▌     | 453/1000 [00:00<00:00, 555.59it/s]\u001B[A\n",
      " 51%|█████     | 509/1000 [00:00<00:00, 548.94it/s]\u001B[A\n",
      " 56%|█████▋    | 564/1000 [00:01<00:00, 548.62it/s]\u001B[A\n",
      " 62%|██████▏   | 622/1000 [00:01<00:00, 556.10it/s]\u001B[A\n",
      " 68%|██████▊   | 680/1000 [00:01<00:00, 562.87it/s]\u001B[A\n",
      " 74%|███████▍  | 742/1000 [00:01<00:00, 579.16it/s]\u001B[A\n",
      " 80%|████████  | 803/1000 [00:01<00:00, 586.38it/s]\u001B[A\n",
      " 87%|████████▋ | 866/1000 [00:01<00:00, 597.51it/s]\u001B[A\n",
      " 93%|█████████▎| 931/1000 [00:01<00:00, 611.87it/s]\u001B[A\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 573.88it/s][A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:00<00:02,  1.74it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:01<00:02,  1.85it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:01<00:01,  1.98it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:02<00:00,  2.04it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:02<00:00,  1.95it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.02it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001B[A\n",
      "  4%|▍         | 44/1000 [00:00<00:02, 434.82it/s]\u001B[A\n",
      " 11%|█         | 109/1000 [00:00<00:01, 557.19it/s]\u001B[A\n",
      " 18%|█▊        | 177/1000 [00:00<00:01, 611.39it/s]\u001B[A\n",
      " 24%|██▍       | 245/1000 [00:00<00:01, 637.55it/s]\u001B[A\n",
      " 31%|███       | 312/1000 [00:00<00:01, 645.84it/s]\u001B[A\n",
      " 38%|███▊      | 378/1000 [00:00<00:00, 650.58it/s]\u001B[A\n",
      " 44%|████▍     | 444/1000 [00:00<00:00, 644.98it/s]\u001B[A\n",
      " 51%|█████     | 509/1000 [00:00<00:00, 643.70it/s]\u001B[A\n",
      " 57%|█████▋    | 574/1000 [00:00<00:00, 641.92it/s]\u001B[A\n",
      " 64%|██████▍   | 640/1000 [00:01<00:00, 645.10it/s]\u001B[A\n",
      " 71%|███████   | 706/1000 [00:01<00:00, 648.48it/s]\u001B[A\n",
      " 77%|███████▋  | 771/1000 [00:01<00:00, 646.91it/s]\u001B[A\n",
      " 84%|████████▎ | 836/1000 [00:01<00:00, 647.47it/s]\u001B[A\n",
      " 90%|█████████ | 902/1000 [00:01<00:00, 651.05it/s]\u001B[A\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 637.27it/s][A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:00<00:01,  3.60it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:00<00:01,  3.72it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:00<00:00,  3.66it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:01<00:00,  3.82it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:01<00:00,  3.68it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.80it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/476 [00:00<?, ?it/s]\u001B[A\n",
      " 11%|█▏        | 54/476 [00:00<00:00, 539.09it/s]\u001B[A\n",
      " 29%|██▉       | 137/476 [00:00<00:00, 708.28it/s]\u001B[A\n",
      " 45%|████▍     | 214/476 [00:00<00:00, 734.82it/s]\u001B[A\n",
      " 62%|██████▏   | 295/476 [00:00<00:00, 760.64it/s]\u001B[A\n",
      " 80%|████████  | 381/476 [00:00<00:00, 794.49it/s]\u001B[A\n",
      "100%|██████████| 476/476 [00:00<00:00, 755.87it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10476 (100.0%) in 1.11 min. Users per second: 157\n"
     ]
    },
    {
     "data": {
      "text/plain": "(       PRECISION PRECISION_RECALL_MIN_DEN    RECALL       MAP MAP_MIN_DEN  \\\n cutoff                                                                      \n 10      0.079553                 0.139499  0.118535  0.038665    0.067016   \n \n              MRR      NDCG        F1  HIT_RATE ARHR_ALL_HITS  ...  \\\n cutoff                                                        ...   \n 10      0.233659  0.125583  0.095209  0.475372      0.298202  ...   \n \n        COVERAGE_USER COVERAGE_USER_HIT USERS_IN_GT DIVERSITY_GINI  \\\n cutoff                                                              \n 10          0.828929           0.39405    0.828929       0.047282   \n \n        SHANNON_ENTROPY RATIO_DIVERSITY_HERFINDAHL RATIO_DIVERSITY_GINI  \\\n cutoff                                                                   \n 10             9.78825                   0.996091             0.137432   \n \n        RATIO_SHANNON_ENTROPY RATIO_AVERAGE_POPULARITY RATIO_NOVELTY  \n cutoff                                                               \n 10                  0.754704                 2.216919      0.348785  \n \n [1 rows x 27 columns],\n 'CUTOFF: 10 - PRECISION: 0.0795533, PRECISION_RECALL_MIN_DEN: 0.1394994, RECALL: 0.1185352, MAP: 0.0386655, MAP_MIN_DEN: 0.0670161, MRR: 0.2336586, NDCG: 0.1255834, F1: 0.0952086, HIT_RATE: 0.4753723, ARHR_ALL_HITS: 0.2982019, NOVELTY: 0.0049351, AVERAGE_POPULARITY: 0.2766839, DIVERSITY_MEAN_INTER_LIST: 0.9573903, DIVERSITY_HERFINDAHL: 0.9957299, COVERAGE_ITEM: 0.2838178, COVERAGE_ITEM_HIT: 0.0712807, ITEMS_IN_GT: 0.8007830, COVERAGE_USER: 0.8289286, COVERAGE_USER_HIT: 0.3940497, USERS_IN_GT: 0.8289286, DIVERSITY_GINI: 0.0472820, SHANNON_ENTROPY: 9.7882502, RATIO_DIVERSITY_HERFINDAHL: 0.9960906, RATIO_DIVERSITY_GINI: 0.1374318, RATIO_SHANNON_ENTROPY: 0.7547042, RATIO_AVERAGE_POPULARITY: 2.2169189, RATIO_NOVELTY: 0.3487849, \\n')"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[10], ignore_users=[])\n",
    "evaluator_test.evaluateRecommender(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d44f3917cd92eabc",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T00:03:16.903199004Z",
     "start_time": "2023-12-11T00:03:09.849557350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10476 (100.0%) in 7.03 sec. Users per second: 1490\n"
     ]
    },
    {
     "data": {
      "text/plain": "(       PRECISION PRECISION_RECALL_MIN_DEN    RECALL       MAP MAP_MIN_DEN  \\\n cutoff                                                                      \n 10      0.077491                 0.135103  0.114663  0.037391    0.064487   \n \n             MRR      NDCG        F1  HIT_RATE ARHR_ALL_HITS  ...  \\\n cutoff                                                       ...   \n 10      0.22838  0.121802  0.092482  0.468977      0.290177  ...   \n \n        COVERAGE_USER COVERAGE_USER_HIT USERS_IN_GT DIVERSITY_GINI  \\\n cutoff                                                              \n 10          0.828929          0.388748    0.828929       0.049943   \n \n        SHANNON_ENTROPY RATIO_DIVERSITY_HERFINDAHL RATIO_DIVERSITY_GINI  \\\n cutoff                                                                   \n 10           10.010709                   0.997321             0.145165   \n \n        RATIO_SHANNON_ENTROPY RATIO_AVERAGE_POPULARITY RATIO_NOVELTY  \n cutoff                                                               \n 10                  0.771856                 1.997246      0.352296  \n \n [1 rows x 27 columns],\n 'CUTOFF: 10 - PRECISION: 0.0774914, PRECISION_RECALL_MIN_DEN: 0.1351029, RECALL: 0.1146631, MAP: 0.0373915, MAP_MIN_DEN: 0.0644866, MRR: 0.2283800, NDCG: 0.1218017, F1: 0.0924819, HIT_RATE: 0.4689767, ARHR_ALL_HITS: 0.2901770, NOVELTY: 0.0049848, AVERAGE_POPULARITY: 0.2492675, DIVERSITY_MEAN_INTER_LIST: 0.9696919, DIVERSITY_HERFINDAHL: 0.9969599, COVERAGE_ITEM: 0.2836828, COVERAGE_ITEM_HIT: 0.0714157, ITEMS_IN_GT: 0.8007830, COVERAGE_USER: 0.8289286, COVERAGE_USER_HIT: 0.3887482, USERS_IN_GT: 0.8289286, DIVERSITY_GINI: 0.0499425, SHANNON_ENTROPY: 10.0107086, RATIO_DIVERSITY_HERFINDAHL: 0.9973211, RATIO_DIVERSITY_GINI: 0.1451650, RATIO_SHANNON_ENTROPY: 0.7718564, RATIO_AVERAGE_POPULARITY: 1.9972460, RATIO_NOVELTY: 0.3522962, \\n')"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final.fit(alphas=[3,1.25])\n",
    "evaluator_test.evaluateRecommender(recoslimmmender_object_dict[\"SLIM_ELASTIC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a67428de0ca1e4f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T00:03:36.199187305Z",
     "start_time": "2023-12-11T00:03:36.193070578Z"
    }
   },
   "outputs": [],
   "source": [
    "td_f = model.training_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a2a140d5f96d3ab1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
