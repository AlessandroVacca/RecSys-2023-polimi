{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from Data_manager.UserUtils import *\n",
    "from Data_manager.split_functions.split_train_validation_random_holdout import \\\n",
    "    split_train_in_two_percentage_global_sample\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "URM_all = getURM_all()\n",
    "\n",
    "with open('URM_train.pkl', 'rb') as f:\n",
    "    URM_train = pickle.load(f)\n",
    "with open('URM_validation.pkl', 'rb') as f:\n",
    "    URM_validation = pickle.load(f)\n",
    "    \n",
    "with open('URM_train_validation.pkl', 'rb') as f:\n",
    "    URM_train_validation = pickle.load(f)\n",
    "with open('URM_test.pkl', 'rb') as f:\n",
    "    URM_test = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T23:20:09.253834463Z",
     "start_time": "2024-01-06T23:20:06.482255426Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Ignoring 2203 (17.4%) Users that have less than 1 test interactions\n"
     ]
    }
   ],
   "source": [
    "# SETUP EVALUATORS\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "\n",
    "#evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=[10])\n",
    "evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T23:20:09.271749049Z",
     "start_time": "2024-01-06T23:20:09.255587578Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserKNNCFRecommender: URM Detected 422 ( 3.3%) users with no interactions.\n",
      "UserKNNCFRecommender: URM Detected 329 ( 1.5%) items with no interactions.\n",
      "UserKNNCFRecommender: URM Detected 205 ( 1.6%) users with no interactions.\n",
      "UserKNNCFRecommender: URM Detected 109 ( 0.5%) items with no interactions.\n",
      "ItemKNNCFRecommender: URM Detected 422 ( 3.3%) users with no interactions.\n",
      "ItemKNNCFRecommender: URM Detected 329 ( 1.5%) items with no interactions.\n",
      "ItemKNNCFRecommender: URM Detected 205 ( 1.6%) users with no interactions.\n",
      "ItemKNNCFRecommender: URM Detected 109 ( 0.5%) items with no interactions.\n",
      "P3alphaRecommender: URM Detected 422 ( 3.3%) users with no interactions.\n",
      "P3alphaRecommender: URM Detected 329 ( 1.5%) items with no interactions.\n",
      "P3alphaRecommender: URM Detected 205 ( 1.6%) users with no interactions.\n",
      "P3alphaRecommender: URM Detected 109 ( 0.5%) items with no interactions.\n",
      "RP3betaRecommender: URM Detected 422 ( 3.3%) users with no interactions.\n",
      "RP3betaRecommender: URM Detected 329 ( 1.5%) items with no interactions.\n",
      "RP3betaRecommender: URM Detected 205 ( 1.6%) users with no interactions.\n",
      "RP3betaRecommender: URM Detected 109 ( 0.5%) items with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 422 ( 3.3%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 329 ( 1.5%) items with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 205 ( 1.6%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 109 ( 0.5%) items with no interactions.\n",
      "MultVAERecommender: URM Detected 422 ( 3.3%) users with no interactions.\n",
      "MultVAERecommender: URM Detected 329 ( 1.5%) items with no interactions.\n",
      "MultVAERecommender: URM Detected 205 ( 1.6%) users with no interactions.\n",
      "MultVAERecommender: URM Detected 109 ( 0.5%) items with no interactions.\n",
      "IALSRecommender: URM Detected 422 ( 3.3%) users with no interactions.\n",
      "IALSRecommender: URM Detected 329 ( 1.5%) items with no interactions.\n",
      "IALSRecommender: URM Detected 205 ( 1.6%) users with no interactions.\n",
      "IALSRecommender: URM Detected 109 ( 0.5%) items with no interactions.\n",
      "SLIMElasticNetRecommender: Loading model from file 'slim_models/slim_t_val'\n",
      "SLIMElasticNetRecommender: Loading complete\n",
      "P3alphaRecommender: Similarity column 22222 (100.0%), 3826.44 column/sec. Elapsed time 5.81 sec\n",
      "RP3betaRecommender: Similarity column 22222 (100.0%), 3497.49 column/sec. Elapsed time 6.35 sec\n",
      "Similarity column 12638 (100.0%), 5396.69 column/sec. Elapsed time 2.34 sec\n",
      "Similarity column 22222 (100.0%), 4437.44 column/sec. Elapsed time 5.01 sec\n",
      "MultVAERecommender: URM Detected 205 ( 1.6%) users with no interactions.\n",
      "MultVAERecommender: URM Detected 109 ( 0.5%) items with no interactions.\n",
      "MultVAERecommender: Loading model from file 'slim_models/MultVAE_train_validation_300'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 00:22:24.869966: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-07 00:22:24.870340: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-07 00:22:24.870593: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-07 00:22:24.870888: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-07 00:22:24.871156: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-07 00:22:24.871356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5437 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from slim_models/MultVAE_train_validation_300/.session/session\n",
      "MultVAERecommender: Loading complete\n",
      "IALSRecommender: URM Detected 422 ( 3.3%) users with no interactions.\n",
      "IALSRecommender: URM Detected 329 ( 1.5%) items with no interactions.\n",
      "IALSRecommender: Loading model from file 'slim_models/IALS_train_validation'\n",
      "IALSRecommender: Loading complete\n",
      "SLIMElasticNetRP3betaTwoScoresHybridRecommender: URM Detected 205 ( 1.6%) users with no interactions.\n",
      "SLIMElasticNetRP3betaTwoScoresHybridRecommender: URM Detected 109 ( 0.5%) items with no interactions.\n",
      "SLIMElasticNetRecommender: Loading model from file 'slim_models/slim_24'\n",
      "SLIMElasticNetRecommender: Loading complete\n",
      "P3alphaRecommender: Similarity column 22222 (100.0%), 3447.94 column/sec. Elapsed time 6.45 sec\n",
      "RP3betaRecommender: Similarity column 22222 (100.0%), 3390.50 column/sec. Elapsed time 6.55 sec\n",
      "Similarity column 12638 (100.0%), 4395.72 column/sec. Elapsed time 2.88 sec\n",
      "Similarity column 22222 (100.0%), 3747.30 column/sec. Elapsed time 5.93 sec\n",
      "MultVAERecommender: Loading model from file 'slim_models/MultVAE_all_opt_300'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 00:22:52.499169: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-07 00:22:52.499585: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-07 00:22:52.499931: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-07 00:22:52.500229: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-07 00:22:52.500480: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-07 00:22:52.500808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5437 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from slim_models/MultVAE_all_opt_300/.session/session\n",
      "MultVAERecommender: Loading complete\n",
      "IALSRecommender: URM Detected 422 ( 3.3%) users with no interactions.\n",
      "IALSRecommender: URM Detected 329 ( 1.5%) items with no interactions.\n",
      "IALSRecommender: Loading model from file 'slim_models/IALS_all'\n",
      "IALSRecommender: Loading complete\n"
     ]
    }
   ],
   "source": [
    "from Hybrid import TwoScoresHybridRecommender\n",
    "from Recommenders.MatrixFactorization.IALSRecommender import IALSRecommender\n",
    "from Recommenders.Neural.MultVAERecommender import MultVAERecommender_OptimizerMask\n",
    "from Recommenders.NonPersonalizedRecommender import TopPop\n",
    "from Recommenders.EASE_R.EASE_R_Recommender import EASE_R_Recommender\n",
    "from Recommenders.KNN.UserKNNCFRecommender import UserKNNCFRecommender\n",
    "from Recommenders.KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "from Recommenders.SLIM.SLIMElasticNetRecommender import SLIMElasticNetRecommender, MultiThreadSLIM_SLIMElasticNetRecommender\n",
    "from Recommenders.GraphBased.P3alphaRecommender import P3alphaRecommender\n",
    "from Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "import pickle\n",
    "\n",
    "\n",
    "MAP_recommender_per_group = {}\n",
    "\n",
    "collaborative_recommender_class = {\n",
    "                                   \"UserKNNCF\": UserKNNCFRecommender,\n",
    "                                   \"ItemKNNCF\": ItemKNNCFRecommender,\n",
    "                                   \"P3alpha\": P3alphaRecommender,\n",
    "                                   \"RP3beta\": RP3betaRecommender,\n",
    "                                   \"SLIM_ELASTIC\": SLIMElasticNetRecommender,\n",
    "                                    \"MULT_VAE\": MultVAERecommender_OptimizerMask,\n",
    "                                    \"IALS\": IALSRecommender\n",
    "                                   }\n",
    "collaborative_recommender_class.items()\n",
    "\n",
    "recommender_object_dict_train = {}\n",
    "recommender_object_dict_train_validation = {}\n",
    "recommender_object_dict_all = {}\n",
    "for label, recommender_class in collaborative_recommender_class.items():\n",
    "    recommender_object = recommender_class(URM_train)\n",
    "    recommender_object_dict_train[label] = recommender_object\n",
    "    \n",
    "    recommender_object = recommender_class(URM_train_validation)\n",
    "    recommender_object_dict_train_validation[label] = recommender_object\n",
    "    \n",
    "    recommender_object = recommender_class(URM_all)\n",
    "    recommender_object_dict_all[label] = recommender_object\n",
    "    \n",
    "    \n",
    "# recommender_object_dict_train[\"SLIM_ELASTIC\"].fit(topK=8894, l1_ratio=0.05565733019999427, alpha=0.0012979360257937668)\n",
    "# recommender_object_dict_train[\"P3alpha\"].fit(topK=76, alpha=0.377201600381895, normalize_similarity=True)\n",
    "# recommender_object_dict_train[\"RP3beta\"].fit(alpha=0.20026352123406477, beta=0.15999879728761354, topK=32)\n",
    "# recommender_object_dict_train[\"UserKNNCF\"].fit(topK=469, shrink=38, similarity='asymmetric', normalize=True,\n",
    "#                                          feature_weighting='TF-IDF', asymmetric_alpha=0.40077406933762383)\n",
    "# recommender_object_dict_train[\"ItemKNNCF\"].fit(topK=31, shrink=435, similarity='tversky', normalize=True,\n",
    "#                                        feature_weighting='BM25', tversky_alpha=0.17113169506422393, tversky_beta=0.5684024974085575)\n",
    "# recommender_object_dict_train[\"TOP_POP\"].fit()\n",
    "# ials = IALSRecommender(URM_train)\n",
    "# ials.load_model(\"slim_models/\", \"IALS_train\")\n",
    "# recommender_object_dict_train[\"IALS\"] = ials\n",
    "# \n",
    "# mv = MultVAERecommender_OptimizerMask(URM_train)\n",
    "# mv.load_model(\"slim_models/\", \"MultVAE_train_300\")\n",
    "# recommender_object_dict_train[\"MULT_VAE\"] = mv\n",
    "\n",
    "recommender_object_dict_train_validation[\"SLIM_ELASTIC\"].load_model(\"slim_models/\", \"slim_t_val\")\n",
    "recommender_object_dict_train_validation[\"P3alpha\"].fit(topK=76, alpha=0.377201600381895, normalize_similarity=True)\n",
    "recommender_object_dict_train_validation[\"RP3beta\"].fit(alpha=0.20026352123406477, beta=0.15999879728761354, topK=32)\n",
    "recommender_object_dict_train_validation[\"UserKNNCF\"].fit(topK=469, shrink=38, similarity='asymmetric', normalize=True,\n",
    "                                         feature_weighting='TF-IDF', asymmetric_alpha=0.40077406933762383)\n",
    "recommender_object_dict_train_validation[\"ItemKNNCF\"].fit(topK=31, shrink=435, similarity='tversky', normalize=True,\n",
    "                                        feature_weighting='BM25', tversky_alpha=0.17113169506422393, tversky_beta=0.5684024974085575)\n",
    "final = MultVAERecommender_OptimizerMask(URM_train_validation)\n",
    "final.load_model(\"slim_models/\", \"MultVAE_train_validation_300\")\n",
    "mv = final\n",
    "recommender_object_dict_train_validation[\"MULT_VAE\"] = mv\n",
    "ials = IALSRecommender(URM_train)\n",
    "ials.load_model(\"slim_models/\", \"IALS_train_validation\")\n",
    "recommender_object_dict_train_validation[\"IALS\"] = ials\n",
    "\n",
    "recommender_object_dict_train_validation[\"hybrid2\"] = TwoScoresHybridRecommender(URM_train_validation, recommender_object_dict_train_validation[\"SLIM_ELASTIC\"], recommender_object_dict_train_validation[\"RP3beta\"])\n",
    "recommender_object_dict_train_validation[\"hybrid2\"].fit(alpha=0.6201320790279279)\n",
    "\n",
    "# recommender_object_dict_train_validation[\"MULT_VAE\"].fit(topK=101, alpha=0.3026342852596128, beta=0.058468783118329024)\n",
    "\n",
    "recommender_object_dict_all[\"SLIM_ELASTIC\"].load_model(\"slim_models/\", \"slim_24\")\n",
    "recommender_object_dict_all[\"P3alpha\"].fit(topK=76, alpha=0.377201600381895, normalize_similarity=True)\n",
    "recommender_object_dict_all[\"RP3beta\"].fit(alpha=0.20026352123406477, beta=0.15999879728761354, topK=32)\n",
    "recommender_object_dict_all[\"UserKNNCF\"].fit(topK=469, shrink=38, similarity='asymmetric', normalize=True,\n",
    "                                         feature_weighting='TF-IDF', asymmetric_alpha=0.40077406933762383)\n",
    "recommender_object_dict_all[\"ItemKNNCF\"].fit(topK=31, shrink=435, similarity='tversky', normalize=True,\n",
    "                                        feature_weighting='BM25', tversky_alpha=0.17113169506422393, tversky_beta=0.5684024974085575)\n",
    "final = MultVAERecommender_OptimizerMask(URM_all)\n",
    "final.load_model(\"slim_models/\", \"MultVAE_all_opt_300\")\n",
    "mv = final\n",
    "recommender_object_dict_all[\"MULT_VAE\"] = mv\n",
    "ials = IALSRecommender(URM_train)\n",
    "ials.load_model(\"slim_models/\", \"IALS_all\")\n",
    "recommender_object_dict_all[\"IALS\"] = ials\n",
    "\n",
    "recommender_object_dict_all[\"hybrid2\"] = TwoScoresHybridRecommender(URM_all, recommender_object_dict_all[\"SLIM_ELASTIC\"], recommender_object_dict_all[\"RP3beta\"])\n",
    "recommender_object_dict_all[\"hybrid2\"].fit(alpha=0.6201320790279279)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T23:22:54.113039428Z",
     "start_time": "2024-01-06T23:22:00.462484079Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T23:43:22.876177273Z",
     "start_time": "2024-01-06T23:43:20.332980681Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRanker\n",
    "import pandas as pd\n",
    "\n",
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "user_id_to_index_mapper = get_user_id_to_index_mapper()\n",
    "data_target = pd.read_csv(filepath_or_buffer=\"data_target_users_test.csv\",\n",
    "                                               sep=\",\",\n",
    "                                               # header=None,\n",
    "                                               dtype={0: int},\n",
    "                                               engine='python')\n",
    "data_target[\"user_id\"] = data_target[\"user_id\"].map(user_id_to_index_mapper)\n",
    "data_target = data_target.dropna()\n",
    "data_target[\"user_id\"] = data_target[\"user_id\"].astype(int)\n",
    "\n",
    "\n",
    "class XGBoostRecommender(BaseRecommender):\n",
    "\n",
    "    RECOMMENDER_NAME = \"XGBoostRecommender\"\n",
    "\n",
    "    def __init__(self,\n",
    "                URM_train,\n",
    "                recommenders,\n",
    "                recommenders_2,\n",
    "                main_recommender,\n",
    "                verbose = True,\n",
    "                n_estimators = 50,\n",
    "                learning_rate = 1e-1,\n",
    "                reg_alpha = 1e-1,\n",
    "                reg_lambda = 1e-1,\n",
    "                max_depth = 20,\n",
    "                max_leaves = 0,\n",
    "                grow_policy = \"depthwise\",\n",
    "                objective = \"pairwise\",\n",
    "                booster = \"gbtree\",\n",
    "                random_seed = None,\n",
    "                ):\n",
    "\n",
    "        super(XGBoostRecommender, self).__init__(URM_train, verbose=verbose)\n",
    "\n",
    "        self.XGB_model = XGBRanker(objective='rank:{}'.format(objective),\n",
    "                                n_estimators = int(n_estimators),\n",
    "                                random_state = random_seed,\n",
    "                                learning_rate = learning_rate,\n",
    "                                reg_alpha = reg_alpha,\n",
    "                                reg_lambda = reg_lambda,\n",
    "                                max_depth = int(max_depth),\n",
    "                                max_leaves = int(max_leaves),\n",
    "                                grow_policy = grow_policy,\n",
    "                                verbosity = 0, # 2 if self.verbose else 0,\n",
    "                                booster = booster,\n",
    "                                enable_categorical = True,\n",
    "                            )\n",
    "        self.recommenders = recommenders\n",
    "        self.recommenders_2 = recommenders_2\n",
    "        self.main_recommender = main_recommender\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "    def fit(self):\n",
    "        xgboost_values = []\n",
    "        xgboost_values_for_item_score = []\n",
    "        suggestions, scores_MAIN = self.recommenders[self.main_recommender].recommend(data_target[\"user_id\"].to_numpy(), cutoff=30, return_scores=True)\n",
    "        suggestions_for_item_score, _ = self.recommenders_2[self.main_recommender].recommend(data_target[\"user_id\"].to_numpy(), cutoff=30, return_scores=True)\n",
    "\n",
    "        other_list = [recommender for recommender in self.recommenders if recommender != self.main_recommender]\n",
    "        other_list_for_item_score = [recommender for recommender in self.recommenders_2 if recommender != self.main_recommender]\n",
    "        \n",
    "        scores_others = {}\n",
    "        scores_others_for_item_score = {}\n",
    "        for name, recommender in self.recommenders.items():\n",
    "            if name != self.main_recommender:\n",
    "                _, scores_others[name] = recommender.recommend(data_target[\"user_id\"].to_numpy(), cutoff=30, return_scores=True)\n",
    "                _, scores_others_for_item_score[name] = self.recommenders_2[name].recommend(data_target[\"user_id\"].to_numpy(), cutoff=30, return_scores=True)\n",
    "    \n",
    "        for i, suggestion in enumerate(suggestions):\n",
    "            for item_id in suggestion:\n",
    "                label = self.URM_train[data_target[\"user_id\"].to_numpy()[i],item_id] == 1\n",
    "                item_popularity = self.URM_train[:,item_id].sum()\n",
    "                user_popularity = self.URM_train[data_target[\"user_id\"].to_numpy()[i],:].sum()\n",
    "                xgboost_values.append([data_target[\"user_id\"].to_numpy()[i], item_id, label, item_popularity, user_popularity,scores_MAIN[i][item_id]]+[scores_others[other][i][item_id] for other in other_list])\n",
    "                \n",
    "                xgboost_values_for_item_score.append([data_target[\"user_id\"].to_numpy()[i], item_id, label, item_popularity, user_popularity,scores_MAIN[i][item_id]]+[scores_others_for_item_score[other][i][item_id] for other in other_list_for_item_score])\n",
    "        xgboost_df = pd.DataFrame(xgboost_values,columns=[\"user_id\", \"item_id\", \"label\",\"item_popularity\", \"user_popularity\", self.main_recommender]+other_list)\n",
    "        xgboost_df_for_item_score = pd.DataFrame(xgboost_values_for_item_score,columns=[\"user_id\", \"item_id\", \"label\",\"item_popularity\", \"user_popularity\", self.main_recommender]+other_list_for_item_score)\n",
    "        \n",
    "        self.y_train = xgboost_df[\"label\"]\n",
    "        self.X_train = xgboost_df.drop(columns=[\"label\"])\n",
    "        self.X_train[\"user_id\"] = self.X_train[\"user_id\"].astype(\"category\")\n",
    "        self.X_train[\"item_id\"] = self.X_train[\"item_id\"].astype(\"category\")\n",
    "        \n",
    "        self.X_train_for_item_score = xgboost_df_for_item_score.drop(columns=[\"label\"])\n",
    "        self.X_train_for_item_score[\"user_id\"] = self.X_train_for_item_score[\"user_id\"].astype(\"category\")\n",
    "        self.X_train_for_item_score[\"item_id\"] = self.X_train_for_item_score[\"item_id\"].astype(\"category\")\n",
    "        \n",
    "        groups = xgboost_df.groupby(\"user_id\").size().values\n",
    "        self.XGB_model.fit(self.X_train,\n",
    "                    self.y_train,\n",
    "                    group=groups,\n",
    "                    verbose=True)\n",
    "    \n",
    "    # def fit(self):\n",
    "    #     xgboost_values = []\n",
    "    #     suggestions, scores_MAIN = self.recommenders[self.main_recommender].recommend(data_target[\"user_id\"].to_numpy(), cutoff=30, return_scores=True)\n",
    "    #     other_list = [recommender for recommender in self.recommenders if recommender != self.main_recommender]\n",
    "    #     scores_others = {}\n",
    "    #     for name, recommender in self.recommenders.items():\n",
    "    #         if name != self.main_recommender:\n",
    "    #             _, scores_others[name] = recommender.recommend(data_target[\"user_id\"].to_numpy(), cutoff=30, return_scores=True)\n",
    "    #     for i, suggestion in enumerate(suggestions):\n",
    "    #         for item_id in suggestion:\n",
    "    #             label = self.URM_train[data_target[\"user_id\"].to_numpy()[i],item_id] == 1\n",
    "    #             item_popularity = self.URM_train[:,item_id].sum()\n",
    "    #             user_popularity = self.URM_train[data_target[\"user_id\"].to_numpy()[i],:].sum()\n",
    "    #             xgboost_values.append([data_target[\"user_id\"].to_numpy()[i], item_id, label, item_popularity, user_popularity,scores_MAIN[i][item_id]]+[scores_others[other][i][item_id] for other in other_list])\n",
    "    #     \n",
    "    #     # add top pop items to users with 0 label\n",
    "    #     # toppop_items, scores_toppop = self.recommenders[\"TopPop\"].recommend(1, cutoff=30, return_scores=True)\n",
    "    #     # for user in data_target[\"user_id\"]:\n",
    "    #     #     xgboost_values.append([user, toppop_items+1, 0, 0]+[0 for other in other_list if other != \"TopPop\"]+[scores_toppop[0][item_map[item]] for item in toppop_items])\n",
    "    #     \n",
    "    #     xgboost_df = pd.DataFrame(xgboost_values,columns=[\"user_id\", \"item_id\", \"label\",\"item_popularity\", \"user_popularity\", self.main_recommender]+other_list)\n",
    "    # \n",
    "    #     self.y_train = xgboost_df[\"label\"]\n",
    "    #     self.X_train = xgboost_df.drop(columns=[\"label\"])\n",
    "    #     self.X_train[\"user_id\"] = self.X_train[\"user_id\"].astype(\"category\")\n",
    "    #     self.X_train[\"item_id\"] = self.X_train[\"item_id\"].astype(\"category\")\n",
    "    #     groups = xgboost_df.groupby(\"user_id\").size().values\n",
    "    #     self.XGB_model.fit(self.X_train,\n",
    "    #                 self.y_train,\n",
    "    #                 group=groups,\n",
    "    #                 verbose=True)\n",
    "    \n",
    "    def get_URM_train(self):\n",
    "        return self.URM_train\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute):\n",
    "        item_weights = np.zeros((len(user_id_array), self.n_items))\n",
    "        for i, user in enumerate(user_id_array):\n",
    "            if user in data_target[\"user_id\"].values-1:\n",
    "                X_to_predict = self.X_train_for_item_score[self.X_train_for_item_score[\"user_id\"] == user]\n",
    "                scores = self.XGB_model.predict(X_to_predict)\n",
    "                scores = (scores - scores.min())/(scores.max() - scores.min() + 1e-12)\n",
    "                item_weights[i][X_to_predict[\"item_id\"]] = scores\n",
    "\n",
    "        return item_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T23:43:42.308202938Z",
     "start_time": "2024-01-06T23:43:42.269995492Z"
    }
   },
   "outputs": [],
   "source": [
    "main_recommender = \"SLIM_ELASTIC\"\n",
    "xg_boost_recommender = XGBoostRecommender(URM_all, recommender_object_dict_train_validation, recommender_object_dict_all, main_recommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-06T23:43:43.275228826Z"
    }
   },
   "outputs": [],
   "source": [
    "xg_boost_recommender.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-06T23:43:18.878160286Z"
    }
   },
   "outputs": [],
   "source": [
    "xg_boost_recommender.X_train[xg_boost_recommender.X_train[\"user_id\"] == 555]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-06T23:43:18.878913132Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "plot_importance(xg_boost_recommender.XGB_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T23:08:13.847648145Z",
     "start_time": "2024-01-06T23:08:12.647187498Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[96], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m evaluation_res \u001B[38;5;241m=\u001B[39m \u001B[43mevaluator_test\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluateRecommender\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxg_boost_recommender\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/projects/rec-sys/RecSys-2023-polimi/Evaluation/Evaluator.py:276\u001B[0m, in \u001B[0;36mEvaluator.evaluateRecommender\u001B[0;34m(self, recommender_object)\u001B[0m\n\u001B[1;32m    273\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time_print \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m    274\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_users_evaluated \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 276\u001B[0m results_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_evaluation_on_selected_users\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrecommender_object\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43musers_to_evaluate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_users_evaluated \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    281\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m cutoff \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcutoff_list:\n",
      "File \u001B[0;32m~/Documents/projects/rec-sys/RecSys-2023-polimi/Evaluation/Evaluator.py:476\u001B[0m, in \u001B[0;36mEvaluatorHoldout._run_evaluation_on_selected_users\u001B[0;34m(self, recommender_object, users_to_evaluate, block_size)\u001B[0m\n\u001B[1;32m    473\u001B[0m     user_batch_start \u001B[38;5;241m=\u001B[39m user_batch_end\n\u001B[1;32m    475\u001B[0m     \u001B[38;5;66;03m# Compute predictions for a batch of users using vectorization, much more efficient than computing it one at a time\u001B[39;00m\n\u001B[0;32m--> 476\u001B[0m     recommended_items_batch_list, scores_batch \u001B[38;5;241m=\u001B[39m \u001B[43mrecommender_object\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecommend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_user_batch_array\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    477\u001B[0m \u001B[43m                                                              \u001B[49m\u001B[43mremove_seen_flag\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexclude_seen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    478\u001B[0m \u001B[43m                                                              \u001B[49m\u001B[43mcutoff\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_cutoff\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    479\u001B[0m \u001B[43m                                                              \u001B[49m\u001B[43mremove_top_pop_flag\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    480\u001B[0m \u001B[43m                                                              \u001B[49m\u001B[43mremove_custom_items_flag\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_items_flag\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    481\u001B[0m \u001B[43m                                                              \u001B[49m\u001B[43mreturn_scores\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m    482\u001B[0m \u001B[43m                                                             \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    484\u001B[0m     results_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_metrics_on_recommendation_list(test_user_batch_array \u001B[38;5;241m=\u001B[39m test_user_batch_array,\n\u001B[1;32m    485\u001B[0m                                                  recommended_items_batch_list \u001B[38;5;241m=\u001B[39m recommended_items_batch_list,\n\u001B[1;32m    486\u001B[0m                                                  scores_batch \u001B[38;5;241m=\u001B[39m scores_batch,\n\u001B[1;32m    487\u001B[0m                                                  results_dict \u001B[38;5;241m=\u001B[39m results_dict)\n\u001B[1;32m    490\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m results_dict\n",
      "File \u001B[0;32m~/Documents/projects/rec-sys/RecSys-2023-polimi/Recommenders/BaseRecommender.py:147\u001B[0m, in \u001B[0;36mBaseRecommender.recommend\u001B[0;34m(self, user_id_array, cutoff, remove_seen_flag, items_to_compute, remove_top_pop_flag, remove_custom_items_flag, return_scores)\u001B[0m\n\u001B[1;32m    143\u001B[0m cutoff \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(cutoff, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mURM_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    145\u001B[0m \u001B[38;5;66;03m# Compute the scores using the model-specific function\u001B[39;00m\n\u001B[1;32m    146\u001B[0m \u001B[38;5;66;03m# Vectorize over all users in user_id_array\u001B[39;00m\n\u001B[0;32m--> 147\u001B[0m scores_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_item_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_id_array\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mitems_to_compute\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mitems_to_compute\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m user_index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(user_id_array)):\n\u001B[1;32m    152\u001B[0m     user_id \u001B[38;5;241m=\u001B[39m user_id_array[user_index]\n",
      "Cell \u001B[0;32mIn[89], line 96\u001B[0m, in \u001B[0;36mXGBoostRecommender._compute_item_score\u001B[0;34m(self, user_id_array, items_to_compute)\u001B[0m\n\u001B[1;32m     94\u001B[0m         X_to_predict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX_train[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX_train[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser_id\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m user]\n\u001B[1;32m     95\u001B[0m         scores \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mXGB_model\u001B[38;5;241m.\u001B[39mpredict(X_to_predict)\n\u001B[0;32m---> 96\u001B[0m         scores \u001B[38;5;241m=\u001B[39m (scores \u001B[38;5;241m-\u001B[39m \u001B[43mscores\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\u001B[38;5;241m/\u001B[39m(scores\u001B[38;5;241m.\u001B[39mmax() \u001B[38;5;241m-\u001B[39m scores\u001B[38;5;241m.\u001B[39mmin() \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1e-12\u001B[39m)\n\u001B[1;32m     97\u001B[0m         item_weights[i][X_to_predict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mitem_id\u001B[39m\u001B[38;5;124m\"\u001B[39m]] \u001B[38;5;241m=\u001B[39m scores\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m item_weights\n",
      "File \u001B[0;32m~/Documents/projects/rec-sys/RecSys-2023-polimi/venv/lib/python3.10/site-packages/numpy/core/_methods.py:45\u001B[0m, in \u001B[0;36m_amin\u001B[0;34m(a, axis, out, keepdims, initial, where)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_amin\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     44\u001B[0m           initial\u001B[38;5;241m=\u001B[39m_NoValue, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mumr_minimum\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhere\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "generateSubmission(xg_boost_recommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>PRECISION_RECALL_MIN_DEN</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>MAP</th>\n",
       "      <th>MAP_MIN_DEN</th>\n",
       "      <th>MRR</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>F1</th>\n",
       "      <th>HIT_RATE</th>\n",
       "      <th>ARHR_ALL_HITS</th>\n",
       "      <th>...</th>\n",
       "      <th>COVERAGE_USER</th>\n",
       "      <th>COVERAGE_USER_HIT</th>\n",
       "      <th>USERS_IN_GT</th>\n",
       "      <th>DIVERSITY_GINI</th>\n",
       "      <th>SHANNON_ENTROPY</th>\n",
       "      <th>RATIO_DIVERSITY_HERFINDAHL</th>\n",
       "      <th>RATIO_DIVERSITY_GINI</th>\n",
       "      <th>RATIO_SHANNON_ENTROPY</th>\n",
       "      <th>RATIO_AVERAGE_POPULARITY</th>\n",
       "      <th>RATIO_NOVELTY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cutoff</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.168823</td>\n",
       "      <td>0.259664</td>\n",
       "      <td>0.207566</td>\n",
       "      <td>0.166033</td>\n",
       "      <td>0.256228</td>\n",
       "      <td>0.62453</td>\n",
       "      <td>0.338491</td>\n",
       "      <td>0.1862</td>\n",
       "      <td>0.626884</td>\n",
       "      <td>0.98549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.804822</td>\n",
       "      <td>0.50453</td>\n",
       "      <td>0.804822</td>\n",
       "      <td>0.044584</td>\n",
       "      <td>9.82538</td>\n",
       "      <td>0.99719</td>\n",
       "      <td>0.127975</td>\n",
       "      <td>0.75688</td>\n",
       "      <td>1.81619</td>\n",
       "      <td>0.301498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRECISION PRECISION_RECALL_MIN_DEN    RECALL       MAP MAP_MIN_DEN  \\\n",
       "cutoff                                                                      \n",
       "10      0.168823                 0.259664  0.207566  0.166033    0.256228   \n",
       "\n",
       "            MRR      NDCG      F1  HIT_RATE ARHR_ALL_HITS  ... COVERAGE_USER  \\\n",
       "cutoff                                                     ...                 \n",
       "10      0.62453  0.338491  0.1862  0.626884       0.98549  ...      0.804822   \n",
       "\n",
       "       COVERAGE_USER_HIT USERS_IN_GT DIVERSITY_GINI SHANNON_ENTROPY  \\\n",
       "cutoff                                                                \n",
       "10               0.50453    0.804822       0.044584         9.82538   \n",
       "\n",
       "       RATIO_DIVERSITY_HERFINDAHL RATIO_DIVERSITY_GINI RATIO_SHANNON_ENTROPY  \\\n",
       "cutoff                                                                         \n",
       "10                        0.99719             0.127975               0.75688   \n",
       "\n",
       "       RATIO_AVERAGE_POPULARITY RATIO_NOVELTY  \n",
       "cutoff                                         \n",
       "10                      1.81619      0.301498  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
